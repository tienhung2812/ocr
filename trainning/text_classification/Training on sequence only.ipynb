{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from keras.optimizers import SGD, Adam, Nadam, RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential,Model,load_model\n",
    "from keras.layers import Embedding,Conv1D,MaxPooling1D\n",
    "from keras.layers.core import Dense, Activation,Dropout ,Flatten\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import text_to_word_sequence,one_hot,Tokenizer\n",
    "from keras.constraints import maxnorm\n",
    "from keras.callbacks import ModelCheckpoint,TensorBoard, ReduceLROnPlateau,EarlyStopping\n",
    "from keras.applications import Xception\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 120\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>l</th>\n",
       "      <th>area_percent</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>phone_num</th>\n",
       "      <th>address</th>\n",
       "      <th>index</th>\n",
       "      <th>content</th>\n",
       "      <th>total</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>thank_you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LIKE CAFE</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.052083</td>\n",
       "      <td>0.018939</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Số 10 Khúc Hạo, Ba Đình, Hà Nội</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.044643</td>\n",
       "      <td>0.025703</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4629719</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.032738</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOA ĐƠN THANH TOÁN.</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.227679</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.020563</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19/01/2014 8:49:59CH</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.327381</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.034226</td>\n",
       "      <td>0.024892</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          sentence         x         y         w         l  \\\n",
       "0                        LIKE CAFE  0.727273  0.031250  0.363636  0.052083   \n",
       "1  Số 10 Khúc Hạo, Ba Đình, Hà Nội  0.515152  0.093750  0.575758  0.044643   \n",
       "2                          4629719  0.878788  0.142857  0.212121  0.032738   \n",
       "3              HOA ĐƠN THANH TOÁN.  0.272727  0.227679  0.575758  0.035714   \n",
       "4             19/01/2014 8:49:59CH  0.060606  0.327381  0.727273  0.034226   \n",
       "\n",
       "   area_percent  title  date  phone_num  address  index  content  total  \\\n",
       "0      0.018939      0     0          0        0      0        0      0   \n",
       "1      0.025703      0     0          0        1      0        0      0   \n",
       "2      0.006944      0     0          1        0      0        0      0   \n",
       "3      0.020563      1     0          0        0      0        0      0   \n",
       "4      0.024892      0     1          0        0      0        0      0   \n",
       "\n",
       "   brand_name  thank_you  \n",
       "0           1          0  \n",
       "1           0          0  \n",
       "2           0          0  \n",
       "3           0          0  \n",
       "4           0          0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = 'data_train.csv'\n",
    "train_df = pd.read_csv(train_path)# Loading a csv file with headers \n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>l</th>\n",
       "      <th>area_percent</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>phone_num</th>\n",
       "      <th>address</th>\n",
       "      <th>index</th>\n",
       "      <th>content</th>\n",
       "      <th>total</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>thank_you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>Ngày: 14/012018 Giờ: 17:25:30</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.354626</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.031938</td>\n",
       "      <td>0.030970</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Khang - Cều Giây - HN</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.113757</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.025573</td>\n",
       "      <td>0.020245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>Service Charge : RM 0.00</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.640148</td>\n",
       "      <td>1.038462</td>\n",
       "      <td>0.024977</td>\n",
       "      <td>0.025938</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>PHIẾU THANH TOÁN</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.566360</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.051248</td>\n",
       "      <td>0.043927</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Giảm 10%: 10.000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.896893</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>0.036723</td>\n",
       "      <td>0.050494</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          sentence         x         y         w         l  \\\n",
       "419  Ngày: 14/012018 Giờ: 17:25:30  0.121212  0.354626  0.969697  0.031938   \n",
       "209          Khang - Cều Giây - HN  0.375000  0.113757  0.791667  0.025573   \n",
       "553       Service Charge : RM 0.00  0.076923  0.640148  1.038462  0.024977   \n",
       "337               PHIẾU THANH TOÁN  0.178571  0.566360  0.857143  0.051248   \n",
       "152               Giảm 10%: 10.000  0.437500  0.896893  1.375000  0.036723   \n",
       "\n",
       "     area_percent  title  date  phone_num  address  index  content  total  \\\n",
       "419      0.030970      0     1          0        0      0        0      0   \n",
       "209      0.020245      0     0          0        1      0        0      0   \n",
       "553      0.025938      0     0          0        0      0        0      1   \n",
       "337      0.043927      1     0          0        0      0        0      0   \n",
       "152      0.050494      0     0          0        0      0        0      1   \n",
       "\n",
       "     brand_name  thank_you  \n",
       "419           0          0  \n",
       "209           0          0  \n",
       "553           0          0  \n",
       "337           0          0  \n",
       "152           0          0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = shuffle(train_df)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[\"sentence\"].fillna(\"fillna\").values\n",
    "Y_train = train_df[[\"title\", \"date\", \"phone_num\",\"address\",\"index\",\"content\",\"total\",\"brand_name\",\"thank_you\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (572,)\n",
      "Shape of Y_train: (572, 9)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train:\",X_train.shape)\n",
    "print(\"Shape of Y_train:\",Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngày: 14/012018 Giờ: 17:25:30\n"
     ]
    }
   ],
   "source": [
    "Tokenizer = Tokenizer()\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Input->Sentence) Length of X_train: (572,)\n",
      "(output->Labels) Length of Y_train: (572, 9)\n",
      "Khang - Cều Giây - HN\n"
     ]
    }
   ],
   "source": [
    "print(\"(Input->Sentence) Length of X_train:\",X_train.shape) # Input -> Input\n",
    "print(\"(output->Labels) Length of Y_train:\",Y_train.shape) # output -> Labels\n",
    "texts = X_train\n",
    "print(texts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer vocabulary size: 1004\n"
     ]
    }
   ],
   "source": [
    "Tokenizer.fit_on_texts(texts) \n",
    "Tokenizer_vocab_size = len(Tokenizer.word_index) + 1\n",
    "print(\"Tokenizer vocabulary size:\",Tokenizer_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(max(X_train,key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Input->Sentence) Length of X_train: (457,)\n",
      "(output->Labels) Length of Y_train: (457, 9)\n"
     ]
    }
   ],
   "source": [
    "print(\"(Input->Sentence) Length of X_train:\",X_train.shape) # Input -> Input\n",
    "print(\"(output->Labels) Length of Y_train:\",Y_train.shape) # output -> Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded_words = Tokenizer.texts_to_sequences(X_train)\n",
    "X_val_encoded_words = Tokenizer.texts_to_sequences(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(output->Labels) Length of Y_train: (457, 9)\n"
     ]
    }
   ],
   "source": [
    "print(\"(output->Labels) Length of Y_train:\",Y_train.shape) # output -> Labelsprint(\"(Input->Sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxWordCount= 5500\n",
    "maxDictionary_size=Tokenizer_vocab_size\n",
    "X_train_encoded_padded_words = sequence.pad_sequences(X_train_encoded_words, maxlen=maxWordCount)\n",
    "X_val_encoded_padded_words = sequence.pad_sequences(X_val_encoded_words, maxlen=maxWordCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Input->Sentence) Length of X_train: (457, 5500)\n",
      "(output->Labels) Length of Y_train: (457, 9)\n"
     ]
    }
   ],
   "source": [
    "print(\"(Input->Sentence) Length of X_train:\",X_train_encoded_padded_words.shape) # Input -> Input\n",
    "print(\"(output->Labels) Length of Y_train:\",Y_train.shape) # output -> Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(457, 9)\n",
      "(115, 9)\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hung/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/hung/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 5500, 32)          32128     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 10)                1720      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1200)              13200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               600500    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 9)                 4509      \n",
      "=================================================================\n",
      "Total params: 652,057\n",
      "Trainable params: 652,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hung/.local/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1200, activation=\"relu\", kernel_constraint=<keras.con...)`\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/hung/.local/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(500, activation=\"relu\", kernel_constraint=<keras.con...)`\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(maxDictionary_size, 32, input_length=maxWordCount)) #to change words to ints\n",
    "# model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Conv1D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    " #hidden layers\n",
    "model.add(LSTM(10))\n",
    "# model.add(Flatten())\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(1200, activation='relu',W_constraint=maxnorm(1)))\n",
    "# model.add(Dropout(0.6))\n",
    "model.add(Dense(500, activation='relu',W_constraint=maxnorm(1)))\n",
    "\n",
    "# model.add(Dropout(0.5))\n",
    " #output layer\n",
    "model.add(Dense(9, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "# adam=Adam(lr=learning_rate, beta_1=0.7, beta_2=0.999, epsilon=1e-08, decay=0.0000001)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.0001\n",
    "epochs = 25\n",
    "batch_size = 32 #32\n",
    "sgd = SGD(lr=learning_rate, nesterov=True, momentum=0.7, decay=1e-4)\n",
    "Nadam = keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Nadam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(457, 5500)\n",
      "(457, 9)\n",
      "(115, 5500)\n",
      "(115, 9)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_encoded_padded_words.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "print(X_val_encoded_padded_words.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hung/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 457 samples, validate on 115 samples\n",
      "Epoch 1/25\n",
      "457/457 [==============================] - 23s 51ms/step - loss: 1.9345 - acc: 0.3414 - val_loss: 1.9486 - val_acc: 0.2087\n",
      "Epoch 2/25\n",
      "457/457 [==============================] - 23s 50ms/step - loss: 1.6800 - acc: 0.3501 - val_loss: 1.5822 - val_acc: 0.3913\n",
      "Epoch 3/25\n",
      "457/457 [==============================] - 22s 49ms/step - loss: 1.4203 - acc: 0.4486 - val_loss: 1.5211 - val_acc: 0.4087\n",
      "Epoch 4/25\n",
      "457/457 [==============================] - 22s 49ms/step - loss: 1.2203 - acc: 0.5120 - val_loss: 1.3875 - val_acc: 0.5130\n",
      "Epoch 5/25\n",
      "457/457 [==============================] - 22s 49ms/step - loss: 1.1095 - acc: 0.5624 - val_loss: 1.3625 - val_acc: 0.4696\n",
      "Epoch 6/25\n",
      "457/457 [==============================] - 22s 49ms/step - loss: 0.9463 - acc: 0.6477 - val_loss: 1.2816 - val_acc: 0.6087\n",
      "Epoch 7/25\n",
      "457/457 [==============================] - 23s 50ms/step - loss: 0.8802 - acc: 0.6477 - val_loss: 1.2543 - val_acc: 0.5739\n",
      "Epoch 8/25\n",
      "457/457 [==============================] - 22s 49ms/step - loss: 0.7586 - acc: 0.7068 - val_loss: 1.3817 - val_acc: 0.5652\n",
      "Epoch 9/25\n",
      "457/457 [==============================] - 23s 49ms/step - loss: 0.7327 - acc: 0.7112 - val_loss: 1.4604 - val_acc: 0.6000\n",
      "Epoch 10/25\n",
      "457/457 [==============================] - 22s 49ms/step - loss: 0.6550 - acc: 0.7681 - val_loss: 1.1681 - val_acc: 0.6087\n",
      "Epoch 11/25\n",
      "457/457 [==============================] - 23s 50ms/step - loss: 0.6106 - acc: 0.7681 - val_loss: 1.1970 - val_acc: 0.6000\n",
      "Epoch 12/25\n",
      "457/457 [==============================] - 23s 50ms/step - loss: 0.6397 - acc: 0.7484 - val_loss: 1.2710 - val_acc: 0.6000\n",
      "Epoch 13/25\n",
      "457/457 [==============================] - 23s 50ms/step - loss: 0.6067 - acc: 0.7484 - val_loss: 1.2640 - val_acc: 0.5913\n",
      "Epoch 14/25\n",
      "457/457 [==============================] - 22s 49ms/step - loss: 0.6574 - acc: 0.7484 - val_loss: 1.2317 - val_acc: 0.6348\n",
      "Epoch 15/25\n",
      "457/457 [==============================] - 23s 50ms/step - loss: 0.5303 - acc: 0.7987 - val_loss: 1.3585 - val_acc: 0.5217\n",
      "Epoch 16/25\n",
      "457/457 [==============================] - 22s 49ms/step - loss: 0.5294 - acc: 0.8031 - val_loss: 1.3122 - val_acc: 0.6522\n",
      "Epoch 17/25\n",
      "457/457 [==============================] - 23s 50ms/step - loss: 0.5413 - acc: 0.7899 - val_loss: 1.2318 - val_acc: 0.6000\n",
      "Epoch 18/25\n",
      "457/457 [==============================] - 29s 63ms/step - loss: 0.4963 - acc: 0.8162 - val_loss: 1.2198 - val_acc: 0.6000\n",
      "Epoch 19/25\n",
      "457/457 [==============================] - 35s 77ms/step - loss: 0.5069 - acc: 0.7965 - val_loss: 1.2220 - val_acc: 0.6174\n",
      "Epoch 20/25\n",
      "457/457 [==============================] - 30s 65ms/step - loss: 0.4395 - acc: 0.8293 - val_loss: 1.4288 - val_acc: 0.5478\n",
      "Epoch 21/25\n",
      "457/457 [==============================] - 27s 59ms/step - loss: 0.4569 - acc: 0.8403 - val_loss: 1.4865 - val_acc: 0.5478\n",
      "Epoch 22/25\n",
      "457/457 [==============================] - 25s 56ms/step - loss: 0.4825 - acc: 0.8228 - val_loss: 1.4200 - val_acc: 0.5478\n",
      "Epoch 23/25\n",
      "457/457 [==============================] - 25s 55ms/step - loss: 0.4293 - acc: 0.8206 - val_loss: 1.3083 - val_acc: 0.6174\n",
      "Epoch 24/25\n",
      "457/457 [==============================] - 23s 51ms/step - loss: 0.4358 - acc: 0.8359 - val_loss: 1.3783 - val_acc: 0.5739\n",
      "Epoch 25/25\n",
      "457/457 [==============================] - 23s 49ms/step - loss: 0.4343 - acc: 0.8534 - val_loss: 1.3402 - val_acc: 0.6261\n"
     ]
    }
   ],
   "source": [
    "history  = model.fit(X_train_encoded_padded_words,Y_train, epochs = epochs, batch_size=batch_size, verbose=1,\n",
    "validation_data=(X_val_encoded_padded_words, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 1s 8ms/step\n",
      "Test accuracy: 0.6260869611864505 %\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_val_encoded_padded_words, Y_val, verbose=1)\n",
    "print('Test accuracy:', score[1],'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.6446081e-03 2.1676740e-02 1.1444956e-01 1.1101150e-02 3.9070779e-01\n",
      "  1.2874262e-03 1.1548631e-04 2.4770917e-02 4.3124634e-01]]\n",
      "Result: brand_name\n"
     ]
    }
   ],
   "source": [
    "phrase = \"Tên menu Đơn giá SL Tiền\"\n",
    "tokens = Tokenizer.texts_to_sequences([phrase])\n",
    "tokens = pad_sequences(tokens, maxlen=5500)\n",
    "prediction = model.predict(np.array(tokens))\n",
    "i,j = np.where(prediction == prediction.max()) #calculates the index of the maximum element of the array across all axis\n",
    "# i->rows, j->columns\n",
    "i = int(i)\n",
    "j = int(j)\n",
    "print(prediction)\n",
    "total_possible_outcomes = [\"area_percent\", \"title\", \"date\", \"phone_num\",\"address\",\"index\",\"content\",\"total\",\"brand_name\",\"thank_you\"]\n",
    "print(\"Result:\",total_possible_outcomes[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model_sequence_only.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_sequence_only.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "with open('tokenizer_sequence_only.pickle', 'wb') as handle:\n",
    "    pickle.dump(Tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

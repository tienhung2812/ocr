{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from keras.optimizers import SGD, Adam, Nadam, RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential,Model,load_model\n",
    "from keras.layers import Embedding,Conv1D,MaxPooling1D\n",
    "from keras.layers.core import Dense, Activation,Dropout ,Flatten\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import text_to_word_sequence,one_hot,Tokenizer\n",
    "from keras.constraints import maxnorm\n",
    "from keras.callbacks import ModelCheckpoint,TensorBoard, ReduceLROnPlateau,EarlyStopping\n",
    "from keras.applications import Xception\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 120\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>l</th>\n",
       "      <th>area_percent</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>phone_num</th>\n",
       "      <th>address</th>\n",
       "      <th>index</th>\n",
       "      <th>content</th>\n",
       "      <th>total</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>thank_you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LIKE CAFE</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.052083</td>\n",
       "      <td>0.018939</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Số 10 Khúc Hạo, Ba Đình, Hà Nội</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.044643</td>\n",
       "      <td>0.025703</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4629719</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.032738</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOA ĐƠN THANH TOÁN.</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.227679</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.020563</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19/01/2014 8:49:59CH</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.327381</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.034226</td>\n",
       "      <td>0.024892</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          sentence         x         y         w         l  \\\n",
       "0                        LIKE CAFE  0.727273  0.031250  0.363636  0.052083   \n",
       "1  Số 10 Khúc Hạo, Ba Đình, Hà Nội  0.515152  0.093750  0.575758  0.044643   \n",
       "2                          4629719  0.878788  0.142857  0.212121  0.032738   \n",
       "3              HOA ĐƠN THANH TOÁN.  0.272727  0.227679  0.575758  0.035714   \n",
       "4             19/01/2014 8:49:59CH  0.060606  0.327381  0.727273  0.034226   \n",
       "\n",
       "   area_percent  title  date  phone_num  address  index  content  total  \\\n",
       "0      0.018939      0     0          0        0      0        0      0   \n",
       "1      0.025703      0     0          0        1      0        0      0   \n",
       "2      0.006944      0     0          1        0      0        0      0   \n",
       "3      0.020563      1     0          0        0      0        0      0   \n",
       "4      0.024892      0     1          0        0      0        0      0   \n",
       "\n",
       "   brand_name  thank_you  \n",
       "0           1          0  \n",
       "1           0          0  \n",
       "2           0          0  \n",
       "3           0          0  \n",
       "4           0          0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = 'data_train.csv'\n",
    "train_df = pd.read_csv(train_path)# Loading a csv file with headers \n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>l</th>\n",
       "      <th>area_percent</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>phone_num</th>\n",
       "      <th>address</th>\n",
       "      <th>index</th>\n",
       "      <th>content</th>\n",
       "      <th>total</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>thank_you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>Ngày: 14/012018 Giờ: 17:25:30</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.354626</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.031938</td>\n",
       "      <td>0.030970</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Khang - Cều Giây - HN</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.113757</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.025573</td>\n",
       "      <td>0.020245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>Service Charge : RM 0.00</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.640148</td>\n",
       "      <td>1.038462</td>\n",
       "      <td>0.024977</td>\n",
       "      <td>0.025938</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>PHIẾU THANH TOÁN</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.566360</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.051248</td>\n",
       "      <td>0.043927</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Giảm 10%: 10.000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.896893</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>0.036723</td>\n",
       "      <td>0.050494</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          sentence         x         y         w         l  \\\n",
       "419  Ngày: 14/012018 Giờ: 17:25:30  0.121212  0.354626  0.969697  0.031938   \n",
       "209          Khang - Cều Giây - HN  0.375000  0.113757  0.791667  0.025573   \n",
       "553       Service Charge : RM 0.00  0.076923  0.640148  1.038462  0.024977   \n",
       "337               PHIẾU THANH TOÁN  0.178571  0.566360  0.857143  0.051248   \n",
       "152               Giảm 10%: 10.000  0.437500  0.896893  1.375000  0.036723   \n",
       "\n",
       "     area_percent  title  date  phone_num  address  index  content  total  \\\n",
       "419      0.030970      0     1          0        0      0        0      0   \n",
       "209      0.020245      0     0          0        1      0        0      0   \n",
       "553      0.025938      0     0          0        0      0        0      1   \n",
       "337      0.043927      1     0          0        0      0        0      0   \n",
       "152      0.050494      0     0          0        0      0        0      1   \n",
       "\n",
       "     brand_name  thank_you  \n",
       "419           0          0  \n",
       "209           0          0  \n",
       "553           0          0  \n",
       "337           0          0  \n",
       "152           0          0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = shuffle(train_df)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[\"sentence\"].fillna(\"fillna\").values\n",
    "Y_train = train_df[[\"title\", \"date\", \"phone_num\",\"address\",\"index\",\"content\",\"total\",\"brand_name\",\"thank_you\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (572,)\n",
      "Shape of Y_train: (572, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train:\",X_train.shape)\n",
    "print(\"Shape of Y_train:\",Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngày: 14/012018 Giờ: 17:25:30\n"
     ]
    }
   ],
   "source": [
    "Tokenizer = Tokenizer()\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Input->Sentence) Length of X_train: (572,)\n",
      "(output->Labels) Length of Y_train: (572, 10)\n",
      "Khang - Cều Giây - HN\n"
     ]
    }
   ],
   "source": [
    "print(\"(Input->Sentence) Length of X_train:\",X_train.shape) # Input -> Input\n",
    "print(\"(output->Labels) Length of Y_train:\",Y_train.shape) # output -> Labels\n",
    "texts = X_train\n",
    "print(texts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer vocabulary size: 869\n"
     ]
    }
   ],
   "source": [
    "Tokenizer.fit_on_texts(texts) \n",
    "Tokenizer_vocab_size = len(Tokenizer.word_index) + 1\n",
    "print(\"Tokenizer vocabulary size:\",Tokenizer_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(max(X_train,key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Input->Sentence) Length of X_train: (457,)\n",
      "(output->Labels) Length of Y_train: (457, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"(Input->Sentence) Length of X_train:\",X_train.shape) # Input -> Input\n",
    "print(\"(output->Labels) Length of Y_train:\",Y_train.shape) # output -> Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded_words = Tokenizer.texts_to_sequences(X_train)\n",
    "X_val_encoded_words = Tokenizer.texts_to_sequences(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(output->Labels) Length of Y_train: (457, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"(output->Labels) Length of Y_train:\",Y_train.shape) # output -> Labelsprint(\"(Input->Sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxWordCount= 5500\n",
    "maxDictionary_size=Tokenizer_vocab_size\n",
    "X_train_encoded_padded_words = sequence.pad_sequences(X_train_encoded_words, maxlen=maxWordCount)\n",
    "X_val_encoded_padded_words = sequence.pad_sequences(X_val_encoded_words, maxlen=maxWordCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Input->Sentence) Length of X_train: (457, 5500)\n",
      "(output->Labels) Length of Y_train: (457, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"(Input->Sentence) Length of X_train:\",X_train_encoded_padded_words.shape) # Input -> Input\n",
    "print(\"(output->Labels) Length of Y_train:\",Y_train.shape) # output -> Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(457, 10)\n",
      "(115, 10)\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0729 20:53:21.953402 4549166528 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 5500, 32)          27808     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 10)                1720      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1200)              13200     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 500)               600500    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 648,238\n",
      "Trainable params: 648,238\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1200, activation=\"relu\", kernel_constraint=<keras.con...)`\n",
      "  from ipykernel import kernelapp as app\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(500, activation=\"relu\", kernel_constraint=<keras.con...)`\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(maxDictionary_size, 32, input_length=maxWordCount)) #to change words to ints\n",
    "# model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Conv1D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    " #hidden layers\n",
    "model.add(LSTM(10))\n",
    "# model.add(Flatten())\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(1200, activation='relu',W_constraint=maxnorm(1)))\n",
    "# model.add(Dropout(0.6))\n",
    "model.add(Dense(500, activation='relu',W_constraint=maxnorm(1)))\n",
    "\n",
    "# model.add(Dropout(0.5))\n",
    " #output layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "# adam=Adam(lr=learning_rate, beta_1=0.7, beta_2=0.999, epsilon=1e-08, decay=0.0000001)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.0001\n",
    "epochs = 25\n",
    "batch_size = 32 #32\n",
    "sgd = SGD(lr=learning_rate, nesterov=True, momentum=0.7, decay=1e-4)\n",
    "Nadam = keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Nadam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(457, 5500)\n",
      "(457, 10)\n",
      "(115, 5500)\n",
      "(115, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_encoded_padded_words.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "print(X_val_encoded_padded_words.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0729 20:53:27.236042 4549166528 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 457 samples, validate on 115 samples\n",
      "Epoch 1/25\n",
      "457/457 [==============================] - 41s 91ms/step - loss: 2.0856 - acc: 0.3370 - val_loss: 1.9987 - val_acc: 0.3391\n",
      "Epoch 2/25\n",
      "457/457 [==============================] - 40s 87ms/step - loss: 1.8364 - acc: 0.3632 - val_loss: 1.7717 - val_acc: 0.4000\n",
      "Epoch 3/25\n",
      "457/457 [==============================] - 39s 84ms/step - loss: 1.6006 - acc: 0.4420 - val_loss: 1.8756 - val_acc: 0.3217\n",
      "Epoch 4/25\n",
      "457/457 [==============================] - 39s 84ms/step - loss: 1.4283 - acc: 0.4661 - val_loss: 1.5097 - val_acc: 0.4087\n",
      "Epoch 5/25\n",
      "457/457 [==============================] - 39s 84ms/step - loss: 1.2199 - acc: 0.5777 - val_loss: 1.4548 - val_acc: 0.4348\n",
      "Epoch 6/25\n",
      "457/457 [==============================] - 40s 87ms/step - loss: 1.0790 - acc: 0.6346 - val_loss: 1.4424 - val_acc: 0.5478\n",
      "Epoch 7/25\n",
      "457/457 [==============================] - 39s 85ms/step - loss: 0.9903 - acc: 0.6521 - val_loss: 1.4055 - val_acc: 0.5652\n",
      "Epoch 8/25\n",
      "457/457 [==============================] - 39s 84ms/step - loss: 0.9214 - acc: 0.6915 - val_loss: 1.4103 - val_acc: 0.5739\n",
      "Epoch 9/25\n",
      "457/457 [==============================] - 38s 84ms/step - loss: 0.8484 - acc: 0.7484 - val_loss: 1.7386 - val_acc: 0.5739\n",
      "Epoch 10/25\n",
      "457/457 [==============================] - 39s 84ms/step - loss: 0.8669 - acc: 0.7352 - val_loss: 1.3343 - val_acc: 0.6261\n",
      "Epoch 11/25\n",
      "457/457 [==============================] - 38s 84ms/step - loss: 0.7960 - acc: 0.7374 - val_loss: 1.3518 - val_acc: 0.6435\n",
      "Epoch 12/25\n",
      "457/457 [==============================] - 38s 84ms/step - loss: 0.7690 - acc: 0.7549 - val_loss: 1.4038 - val_acc: 0.5913\n",
      "Epoch 13/25\n",
      "457/457 [==============================] - 39s 84ms/step - loss: 0.7242 - acc: 0.7812 - val_loss: 1.4425 - val_acc: 0.6000\n",
      "Epoch 14/25\n",
      "457/457 [==============================] - 39s 85ms/step - loss: 0.7013 - acc: 0.7921 - val_loss: 1.4149 - val_acc: 0.6522\n",
      "Epoch 15/25\n",
      "457/457 [==============================] - 39s 85ms/step - loss: 0.6818 - acc: 0.7921 - val_loss: 1.5457 - val_acc: 0.5739\n",
      "Epoch 16/25\n",
      "457/457 [==============================] - 38s 84ms/step - loss: 0.7347 - acc: 0.7724 - val_loss: 1.2830 - val_acc: 0.6522\n",
      "Epoch 17/25\n",
      "457/457 [==============================] - 39s 85ms/step - loss: 0.5986 - acc: 0.8403 - val_loss: 1.7468 - val_acc: 0.5739\n",
      "Epoch 18/25\n",
      "457/457 [==============================] - 39s 84ms/step - loss: 0.6694 - acc: 0.8009 - val_loss: 1.5619 - val_acc: 0.5913\n",
      "Epoch 19/25\n",
      "457/457 [==============================] - 38s 84ms/step - loss: 0.6206 - acc: 0.8206 - val_loss: 1.2920 - val_acc: 0.6348\n",
      "Epoch 20/25\n",
      "457/457 [==============================] - 38s 84ms/step - loss: 0.5996 - acc: 0.8096 - val_loss: 2.1848 - val_acc: 0.5217\n",
      "Epoch 21/25\n",
      "457/457 [==============================] - 39s 84ms/step - loss: 0.6460 - acc: 0.8315 - val_loss: 1.4025 - val_acc: 0.6435\n",
      "Epoch 22/25\n",
      "457/457 [==============================] - 39s 86ms/step - loss: 0.5970 - acc: 0.8228 - val_loss: 1.4695 - val_acc: 0.6261\n",
      "Epoch 23/25\n",
      "457/457 [==============================] - 39s 84ms/step - loss: 0.6091 - acc: 0.8315 - val_loss: 1.2949 - val_acc: 0.6696\n",
      "Epoch 24/25\n",
      "457/457 [==============================] - 38s 84ms/step - loss: 0.6184 - acc: 0.8053 - val_loss: 1.5737 - val_acc: 0.6957\n",
      "Epoch 25/25\n",
      "457/457 [==============================] - 40s 89ms/step - loss: 0.5744 - acc: 0.8315 - val_loss: 1.4279 - val_acc: 0.6609\n"
     ]
    }
   ],
   "source": [
    "history  = model.fit(X_train_encoded_padded_words,Y_train, epochs = epochs, batch_size=batch_size, verbose=1,\n",
    "validation_data=(X_val_encoded_padded_words, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 1s 11ms/step\n",
      "Test accuracy: 0.6608695636624875 %\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_val_encoded_padded_words, Y_val, verbose=1)\n",
    "print('Test accuracy:', score[1],'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.8071234e-02 1.3067013e-07 3.9153777e-02 2.0538312e-03 5.3152162e-01\n",
      "  3.8352391e-01 3.8820494e-03 4.9205173e-05 8.4206105e-05 1.6600216e-03]]\n",
      "Result: address\n"
     ]
    }
   ],
   "source": [
    "phrase = \"Tên menu Đơn giá SL Tiền\"\n",
    "tokens = Tokenizer.texts_to_sequences([phrase])\n",
    "tokens = pad_sequences(tokens, maxlen=5500)\n",
    "prediction = model.predict(np.array(tokens))\n",
    "i,j = np.where(prediction == prediction.max()) #calculates the index of the maximum element of the array across all axis\n",
    "# i->rows, j->columns\n",
    "i = int(i)\n",
    "j = int(j)\n",
    "print(prediction)\n",
    "total_possible_outcomes = [\"area_percent\", \"title\", \"date\", \"phone_num\",\"address\",\"index\",\"content\",\"total\",\"brand_name\",\"thank_you\"]\n",
    "print(\"Result:\",total_possible_outcomes[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(Tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Importing Necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from keras.optimizers import SGD, Adam, Nadam, RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential,Model,load_model\n",
    "from keras.layers import Embedding,Conv1D,MaxPooling1D\n",
    "from keras.layers.core import Dense, Activation,Dropout ,Flatten\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import text_to_word_sequence,one_hot,Tokenizer\n",
    "from keras.constraints import maxnorm\n",
    "from keras.callbacks import ModelCheckpoint,TensorBoard, ReduceLROnPlateau,EarlyStopping\n",
    "from keras.applications import Xception\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initialize the seed inorder to get the same output every single time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 120\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Loading the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>BookRestaurant</th>\n",
       "      <th>GetWeather</th>\n",
       "      <th>PlayMusic</th>\n",
       "      <th>RateBook</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>book The Middle East restaurant in IN for noon</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Book a table at T-Rex distant from Halsey St.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'd like to eat at a taverna that serves chili...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have a party of four in Japan and need a res...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Please make a restaurant reservation for somew...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  BookRestaurant  \\\n",
       "0     book The Middle East restaurant in IN for noon               1   \n",
       "1      Book a table at T-Rex distant from Halsey St.               1   \n",
       "2  I'd like to eat at a taverna that serves chili...               1   \n",
       "3  I have a party of four in Japan and need a res...               1   \n",
       "4  Please make a restaurant reservation for somew...               1   \n",
       "\n",
       "   GetWeather  PlayMusic  RateBook  \n",
       "0           0          0         0  \n",
       "1           0          0         0  \n",
       "2           0          0         0  \n",
       "3           0          0         0  \n",
       "4           0          0         0  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = './data/train/train.csv'\n",
    "train_df = pd.read_csv(train_path)# Loading a csv file with headers \n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Shuffling the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>BookRestaurant</th>\n",
       "      <th>GetWeather</th>\n",
       "      <th>PlayMusic</th>\n",
       "      <th>RateBook</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>book a spot for 1 close to geraldine's house</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3696</th>\n",
       "      <td>What is the weather in Deeth</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5490</th>\n",
       "      <td>play music by Rodney Whitaker</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5222</th>\n",
       "      <td>play top-twenty song from 2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <td>I want to book a restaurant in Barbados that s...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  BookRestaurant  \\\n",
       "256        book a spot for 1 close to geraldine's house               1   \n",
       "3696                       What is the weather in Deeth               0   \n",
       "5490                      play music by Rodney Whitaker               0   \n",
       "5222                     play top-twenty song from 2015               0   \n",
       "1952  I want to book a restaurant in Barbados that s...               1   \n",
       "\n",
       "      GetWeather  PlayMusic  RateBook  \n",
       "256            0          0         0  \n",
       "3696           1          0         0  \n",
       "5490           0          1         0  \n",
       "5222           0          1         0  \n",
       "1952           0          0         0  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = shuffle(train_df)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Now saving the dataframe column(X_train,Y_train) as a numpy array\n",
    "\n",
    "Here,\n",
    "- X_train -> Its a feature(INPUT)\n",
    "- Y_tain -> Its a label(OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[\"sentence\"].fillna(\"fillna\").values\n",
    "Y_train = train_df[[\"BookRestaurant\", \"GetWeather\", \"PlayMusic\", \"RateBook\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (7929,)\n",
      "Shape of Y_train: (7929, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train:\",X_train.shape)\n",
    "print(\"Shape of Y_train:\",Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------First 2 rows of X_train numpy array--------------------\n",
      "0 . book a spot for 1 close to geraldine's house\n",
      "1 . What is the weather in Deeth\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------------------First 2 rows of X_train numpy array--------------------\")\n",
    "for i in range(0,2):\n",
    "    print(i,'.',X_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Setting up Tokenizer class\n",
    "The Tokenizer class in Keras has various methods which help to prepare text so it can be used in neural network models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book a spot for 1 close to geraldine's house\n"
     ]
    }
   ],
   "source": [
    "Tokenizer = Tokenizer()\n",
    "print(X_train[0]) # training dataset 1st sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Input->Sentence) Length of X_train: (7929,)\n",
      "(output->Labels) Length of Y_train: (7929, 4)\n",
      "book a spot for 1 close to geraldine's house\n"
     ]
    }
   ],
   "source": [
    "print(\"(Input->Sentence) Length of X_train:\",X_train.shape) # Input -> Input\n",
    "print(\"(output->Labels) Length of Y_train:\",Y_train.shape) # output -> Labels\n",
    "texts = X_train\n",
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer vocabulary size: 7526\n"
     ]
    }
   ],
   "source": [
    "Tokenizer.fit_on_texts(texts) \n",
    "Tokenizer_vocab_size = len(Tokenizer.word_index) + 1\n",
    "print(\"Tokenizer vocabulary size:\",Tokenizer_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Now find the length of longest sublist in X_train,X_test and set it as max Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(max(X_train,key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxWordCount= 5500\n",
    "maxDictionary_size=Tokenizer_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Input->Sentence) Length of X_train: (7929,)\n",
      "(output->Labels) Length of Y_train: (7929, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"(Input->Sentence) Length of X_train:\",X_train.shape) # Input -> Input\n",
    "print(\"(output->Labels) Length of Y_train:\",Y_train.shape) # output -> Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Now setting up data for validation and training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = 1586 # Test samples for validation\n",
    "\n",
    "\n",
    "# Phase 1: Setting up data for training\n",
    "X_train = X_train[num_test_samples:] # 1586 samples to n ----> Sentence (Input)\n",
    "Y_train = Y_train[num_test_samples:] # 1586 samples to n ----> Labels (Output)\n",
    "\n",
    "# Phase 2: Setting up data for validation\n",
    "X_val = X_train[:num_test_samples] # First 1586 Samples --> Sentence (Input)\n",
    "Y_val = Y_train[:num_test_samples] # First 1586 Samples --> Labels (Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Input->Sentence) Length of X_train: (6343,)\n",
      "(output->Labels) Length of Y_train: (6343, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"(Input->Sentence) Length of X_train:\",X_train.shape) # Input -> Input\n",
    "print(\"(output->Labels) Length of Y_train:\",Y_train.shape) # output -> Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  11.  Encoding Operation--->Turn text into a numerical array(using Tokenizer.texts_to_sequences)--->Uses Tokenizer_word_index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 3: Encoding Operation--->Turn text into a numerical array(using Tokenizer.texts_to_sequences)--->Uses Tokenizer_word_index.\n",
    "X_train_encoded_words = Tokenizer.texts_to_sequences(X_train)\n",
    "X_val_encoded_words = Tokenizer.texts_to_sequences(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(output->Labels) Length of Y_train: (6343, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"(output->Labels) Length of Y_train:\",Y_train.shape) # output -> Labelsprint(\"(Input->Sentence) Length of X_train:\",len(X_train_encoded_words)) # Input -> Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Padding all text to same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded_padded_words = sequence.pad_sequences(X_train_encoded_words, maxlen=maxWordCount)\n",
    "X_val_encoded_padded_words = sequence.pad_sequences(X_val_encoded_words, maxlen=maxWordCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Input->Sentence) Length of X_train: (6343, 5500)\n",
      "(output->Labels) Length of Y_train: (6343, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"(Input->Sentence) Length of X_train:\",X_train_encoded_padded_words.shape) # Input -> Input\n",
    "print(\"(output->Labels) Length of Y_train:\",Y_train.shape) # output -> Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6343, 4)\n",
      "(1586, 4)\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Now defining the neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 5500, 32)          240832    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 10)                1720      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1200)              13200     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 500)               600500    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4)                 2004      \n",
      "=================================================================\n",
      "Total params: 858,256\n",
      "Trainable params: 858,256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1200, activation=\"relu\", kernel_constraint=<keras.con...)`\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(500, activation=\"relu\", kernel_constraint=<keras.con...)`\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "#model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(maxDictionary_size, 32, input_length=maxWordCount)) #to change words to ints\n",
    "# model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Conv1D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    " #hidden layers\n",
    "model.add(LSTM(10))\n",
    "# model.add(Flatten())\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(1200, activation='relu',W_constraint=maxnorm(1)))\n",
    "# model.add(Dropout(0.6))\n",
    "model.add(Dense(500, activation='relu',W_constraint=maxnorm(1)))\n",
    "\n",
    "# model.add(Dropout(0.5))\n",
    " #output layer\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "# adam=Adam(lr=learning_rate, beta_1=0.7, beta_2=0.999, epsilon=1e-08, decay=0.0000001)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Now setting up learning rate,optimizers,batch_size, and compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.0001\n",
    "epochs = 25\n",
    "batch_size = 32 #32\n",
    "sgd = SGD(lr=learning_rate, nesterov=True, momentum=0.7, decay=1e-4)\n",
    "Nadam = keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Nadam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6343, 5500)\n",
      "(6343, 4)\n",
      "(1586, 5500)\n",
      "(1586, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_encoded_padded_words.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "print(X_val_encoded_padded_words.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6343 samples, validate on 1586 samples\n",
      "Epoch 1/25\n",
      "6343/6343 [==============================] - 430s 68ms/step - loss: 0.3403 - acc: 0.8490 - val_loss: 0.0367 - val_acc: 0.9893\n",
      "Epoch 2/25\n",
      "6343/6343 [==============================] - 464s 73ms/step - loss: 0.1060 - acc: 0.9600 - val_loss: 0.0087 - val_acc: 0.9968\n",
      "Epoch 3/25\n",
      "1888/6343 [=======>......................] - ETA: 4:55 - loss: 0.0793 - acc: 0.9709"
     ]
    }
   ],
   "source": [
    "# model.fit(Train_input,Train_output,epochs,batch_size,verbose,validation_data=(val_input,val_output))\n",
    "history  = model.fit(X_train_encoded_padded_words,Y_train, epochs = epochs, batch_size=batch_size, verbose=1,\n",
    "                    validation_data=(X_val_encoded_padded_words, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Calculating the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=============================== Score =========================================\")\n",
    "# Finally calucating the score.\n",
    "score = model.evaluate(X_val_encoded_padded_words, Y_val, verbose=1)\n",
    "print('Test accuracy:', score[1],'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. Predicting the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = \"Book The Oriel in Allison for a party of four.\"\n",
    "tokens = Tokenizer.texts_to_sequences([phrase])\n",
    "tokens = pad_sequences(tokens, maxlen=5500)\n",
    "prediction = model.predict(np.array(tokens))\n",
    "i,j = np.where(prediction == prediction.max()) #calculates the index of the maximum element of the array across all axis\n",
    "# i->rows, j->columns\n",
    "i = int(i)\n",
    "j = int(j)\n",
    "print(prediction)\n",
    "total_possible_outcomes = ['1_BookRestaurant','2_GetWeather','3_PlayMusic','4_RateBook']\n",
    "print(\"Result:\",total_possible_outcomes[j])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. Saving your model to json and weights as HDF5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"./data/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"./data/model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. Storing Tokenizer for storing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving\n",
    "with open('./data/tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(Tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

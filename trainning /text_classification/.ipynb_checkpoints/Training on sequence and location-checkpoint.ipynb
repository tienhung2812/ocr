{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from keras.optimizers import SGD, Adam, Nadam, RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential,Model,load_model\n",
    "from keras.layers import Embedding,Conv1D,MaxPooling1D\n",
    "from keras.layers.core import Dense, Activation,Dropout ,Flatten\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import text_to_word_sequence,one_hot,Tokenizer\n",
    "from keras.constraints import maxnorm\n",
    "from keras.callbacks import ModelCheckpoint,TensorBoard, ReduceLROnPlateau,EarlyStopping\n",
    "from keras.applications import Xception\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 120\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>l</th>\n",
       "      <th>area_percent</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>phone_num</th>\n",
       "      <th>address</th>\n",
       "      <th>index</th>\n",
       "      <th>content</th>\n",
       "      <th>total</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>thank_you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LIKE CAFE</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.052083</td>\n",
       "      <td>0.018939</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Số 10 Khúc Hạo, Ba Đình, Hà Nội</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.044643</td>\n",
       "      <td>0.025703</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4629719</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.032738</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOA ĐƠN THANH TOÁN.</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.227679</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.020563</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19/01/2014 8:49:59CH</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.327381</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.034226</td>\n",
       "      <td>0.024892</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          sentence         x         y         w         l  \\\n",
       "0                        LIKE CAFE  0.727273  0.031250  0.363636  0.052083   \n",
       "1  Số 10 Khúc Hạo, Ba Đình, Hà Nội  0.515152  0.093750  0.575758  0.044643   \n",
       "2                          4629719  0.878788  0.142857  0.212121  0.032738   \n",
       "3              HOA ĐƠN THANH TOÁN.  0.272727  0.227679  0.575758  0.035714   \n",
       "4             19/01/2014 8:49:59CH  0.060606  0.327381  0.727273  0.034226   \n",
       "\n",
       "   area_percent  title  date  phone_num  address  index  content  total  \\\n",
       "0      0.018939      0     0          0        0      0        0      0   \n",
       "1      0.025703      0     0          0        1      0        0      0   \n",
       "2      0.006944      0     0          1        0      0        0      0   \n",
       "3      0.020563      1     0          0        0      0        0      0   \n",
       "4      0.024892      0     1          0        0      0        0      0   \n",
       "\n",
       "   brand_name  thank_you  \n",
       "0           1          0  \n",
       "1           0          0  \n",
       "2           0          0  \n",
       "3           0          0  \n",
       "4           0          0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = 'data_train.csv'\n",
    "raw_train_df = pd.read_csv(train_path)# Loading a csv file with headers \n",
    "raw_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>info</th>\n",
       "      <th>index</th>\n",
       "      <th>content</th>\n",
       "      <th>total</th>\n",
       "      <th>thank_you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>Ngày: 14/012018 Giờ: 17:25:30 1 3 9 0 0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Khang - Cều Giây - HN 3 1 7 0 0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>Service Charge : RM 0.00 0 6 10 0 0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>PHIẾU THANH TOÁN 1 5 8 0 0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Giảm 10%: 10.000 4 8 13 0 0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    sentence brand_name info index content  \\\n",
       "419  Ngày: 14/012018 Giờ: 17:25:30 1 3 9 0 0          0    1     0       0   \n",
       "209          Khang - Cều Giây - HN 3 1 7 0 0          0    1     0       0   \n",
       "553      Service Charge : RM 0.00 0 6 10 0 0          0    0     0       0   \n",
       "337               PHIẾU THANH TOÁN 1 5 8 0 0          0    1     0       0   \n",
       "152              Giảm 10%: 10.000 4 8 13 0 0          0    0     0       0   \n",
       "\n",
       "    total thank_you  \n",
       "419     0         0  \n",
       "209     0         0  \n",
       "553     1         0  \n",
       "337     0         0  \n",
       "152     1         0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group all data to one pandas\n",
    "# Divide x,y,w,l,area_percent into 10x10\n",
    "sentence_col_group = [\"x\",\"y\",\"w\",\"l\",\"area_percent\"]\n",
    "info_group_result_data = [\"title\", \"date\", \"phone_num\",\"address\"] \n",
    "# raw_col = [\"sentence\",\"index\",\"content\",\"total\",\"brand_name\",\"thank_you\"]\n",
    "train_df = pd.DataFrame(columns=[\"sentence\",\"brand_name\",\"info\",\"index\",\"content\",\"total\",\"thank_you\"])\n",
    "\n",
    "for index, raw_row in raw_train_df.iterrows():\n",
    "    sentence = raw_row[\"sentence\"]\n",
    "#     Append \"x\",\"y\",\"w\",\"l\",\"area_percent\" into sentence\n",
    "    for col_name in sentence_col_group:\n",
    "        sentence += ' ' + str(int(raw_row[col_name]*10))\n",
    "        \n",
    "    # Group \"title\", \"date\", \"phone_num\",\"address\" into info col\n",
    "    info = 0\n",
    "    for col_name in info_group_result_data:\n",
    "        if raw_row[col_name] == 1:\n",
    "            info = 1\n",
    "    \n",
    "    data = {\n",
    "        \"sentence\" : sentence,\n",
    "        \"brand_name\" : raw_row[\"brand_name\"],\n",
    "        \"info\" : info,\n",
    "        \"index\" : raw_row[\"index\"],\n",
    "        \"content\": raw_row[\"content\"],\n",
    "        \"total\": raw_row[\"total\"],\n",
    "        \"thank_you\" : raw_row[\"thank_you\"]\n",
    "    }\n",
    "    \n",
    "    #Check data\n",
    "    count = 0\n",
    "    for col in ['brand_name', 'info', 'index', 'content', 'total', 'thank_you']:\n",
    "        if data[col] == 0:\n",
    "            count += 1\n",
    "    if count == 6:\n",
    "        print(\"Error \")\n",
    "        print(\"Raw row: \",raw_row)\n",
    "        print(\"Data: \",data)\n",
    "        \n",
    "    \n",
    "    train_df.loc[index] = data\n",
    "    \n",
    "train_df = shuffle(train_df)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done !\n"
     ]
    }
   ],
   "source": [
    "# Check data is null?\n",
    "# print(train_df.columns)\n",
    "for index,row in train_df.iterrows():\n",
    "    count = 0\n",
    "    for col in ['brand_name', 'info', 'index', 'content', 'total', 'thank_you']:\n",
    "        if row[col] == 0:\n",
    "            count += 1\n",
    "    if count == len(col):\n",
    "        print(row)\n",
    "print(\"Done !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[\"sentence\"].fillna(\"fillna\").values\n",
    "Y_train = train_df[['brand_name', 'info', 'index', 'content', 'total', 'thank_you']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (572,)\n",
      "Shape of Y_train: (572, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train:\",X_train.shape)\n",
    "print(\"Shape of Y_train:\",Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngày: 14/012018 Giờ: 17:25:30 1 3 9 0 0\n"
     ]
    }
   ],
   "source": [
    "Tokenizer = Tokenizer()\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Input->Sentence) Length of X_train: (572,)\n",
      "(output->Labels) Length of Y_train: (572, 6)\n",
      "Ngày: 14/012018 Giờ: 17:25:30 1 3 9 0 0\n"
     ]
    }
   ],
   "source": [
    "print(\"(Input->Sentence) Length of X_train:\",X_train.shape) # Input -> Input\n",
    "print(\"(output->Labels) Length of Y_train:\",Y_train.shape) # output -> Labels\n",
    "texts = X_train\n",
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer vocabulary size: 1004\n"
     ]
    }
   ],
   "source": [
    "Tokenizer.fit_on_texts(texts) \n",
    "Tokenizer_vocab_size = len(Tokenizer.word_index) + 1\n",
    "print(\"Tokenizer vocabulary size:\",Tokenizer_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(max(X_train,key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Input->Sentence) Length of X_train: (457,)\n",
      "(output->Labels) Length of Y_train: (457, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"(Input->Sentence) Length of X_train:\",X_train.shape) # Input -> Input\n",
    "print(\"(output->Labels) Length of Y_train:\",Y_train.shape) # output -> Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded_words = Tokenizer.texts_to_sequences(X_train)\n",
    "X_val_encoded_words = Tokenizer.texts_to_sequences(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(output->Labels) Length of Y_train: (457, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"(output->Labels) Length of Y_train:\",Y_train.shape) # output -> Labelsprint(\"(Input->Sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxWordCount= 5500\n",
    "maxDictionary_size=Tokenizer_vocab_size\n",
    "X_train_encoded_padded_words = sequence.pad_sequences(X_train_encoded_words, maxlen=maxWordCount)\n",
    "X_val_encoded_padded_words = sequence.pad_sequences(X_val_encoded_words, maxlen=maxWordCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Input->Sentence) Length of X_train: (457, 5500)\n",
      "(output->Labels) Length of Y_train: (457, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"(Input->Sentence) Length of X_train:\",X_train_encoded_padded_words.shape) # Input -> Input\n",
    "print(\"(output->Labels) Length of Y_train:\",Y_train.shape) # output -> Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(457, 6)\n",
      "(115, 6)\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hung/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/hung/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 5500, 32)          32128     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 10)                1720      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1200)              13200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               600500    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 3006      \n",
      "=================================================================\n",
      "Total params: 650,554\n",
      "Trainable params: 650,554\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hung/.local/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1200, activation=\"relu\", kernel_constraint=<keras.con...)`\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/hung/.local/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(500, activation=\"relu\", kernel_constraint=<keras.con...)`\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(maxDictionary_size, 32, input_length=maxWordCount)) #to change words to ints\n",
    "# model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Conv1D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    " #hidden layers\n",
    "model.add(LSTM(10))\n",
    "# model.add(Flatten())\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(1200, activation='relu',W_constraint=maxnorm(1)))\n",
    "# model.add(Dropout(0.6))\n",
    "model.add(Dense(500, activation='relu',W_constraint=maxnorm(1)))\n",
    "\n",
    "# model.add(Dropout(0.5))\n",
    " #output layer\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "# adam=Adam(lr=learning_rate, beta_1=0.7, beta_2=0.999, epsilon=1e-08, decay=0.0000001)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.0001\n",
    "epochs = 25\n",
    "batch_size = 32 #32\n",
    "sgd = SGD(lr=learning_rate, nesterov=True, momentum=0.7, decay=1e-4)\n",
    "Nadam = keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Nadam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(457, 5500)\n",
      "(457, 6)\n",
      "(115, 5500)\n",
      "(115, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_encoded_padded_words.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "print(X_val_encoded_padded_words.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hung/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 457 samples, validate on 115 samples\n",
      "Epoch 1/25\n",
      "457/457 [==============================] - 31s 68ms/step - loss: 1.5747 - acc: 0.3435 - val_loss: 1.5754 - val_acc: 0.2087\n",
      "Epoch 2/25\n",
      "457/457 [==============================] - 22s 48ms/step - loss: 1.4533 - acc: 0.3698 - val_loss: 1.3855 - val_acc: 0.4087\n",
      "Epoch 3/25\n",
      "457/457 [==============================] - 22s 48ms/step - loss: 1.2380 - acc: 0.5208 - val_loss: 1.1236 - val_acc: 0.5565\n",
      "Epoch 4/25\n",
      "457/457 [==============================] - 22s 48ms/step - loss: 0.9699 - acc: 0.6499 - val_loss: 1.5186 - val_acc: 0.4522\n",
      "Epoch 5/25\n",
      "457/457 [==============================] - 22s 49ms/step - loss: 0.8875 - acc: 0.6586 - val_loss: 1.0812 - val_acc: 0.6261\n",
      "Epoch 6/25\n",
      "457/457 [==============================] - 22s 47ms/step - loss: 0.8021 - acc: 0.7046 - val_loss: 1.0017 - val_acc: 0.6348\n",
      "Epoch 7/25\n",
      "457/457 [==============================] - 22s 47ms/step - loss: 0.7416 - acc: 0.7374 - val_loss: 1.0319 - val_acc: 0.6087\n",
      "Epoch 8/25\n",
      "457/457 [==============================] - 22s 48ms/step - loss: 0.6558 - acc: 0.7549 - val_loss: 1.0654 - val_acc: 0.6261\n",
      "Epoch 9/25\n",
      "457/457 [==============================] - 22s 47ms/step - loss: 0.6499 - acc: 0.7812 - val_loss: 1.5168 - val_acc: 0.5565\n",
      "Epoch 10/25\n",
      "457/457 [==============================] - 22s 47ms/step - loss: 0.5574 - acc: 0.8053 - val_loss: 1.1681 - val_acc: 0.6000\n",
      "Epoch 11/25\n",
      "457/457 [==============================] - 22s 48ms/step - loss: 0.7060 - acc: 0.7549 - val_loss: 1.0589 - val_acc: 0.6000\n",
      "Epoch 12/25\n",
      "457/457 [==============================] - 22s 47ms/step - loss: 0.5595 - acc: 0.7834 - val_loss: 1.2603 - val_acc: 0.6087\n",
      "Epoch 13/25\n",
      "457/457 [==============================] - 22s 47ms/step - loss: 0.4627 - acc: 0.8206 - val_loss: 1.1968 - val_acc: 0.6087\n",
      "Epoch 14/25\n",
      "457/457 [==============================] - 22s 48ms/step - loss: 0.4506 - acc: 0.8162 - val_loss: 1.3941 - val_acc: 0.5826\n",
      "Epoch 15/25\n",
      "457/457 [==============================] - 22s 47ms/step - loss: 0.4251 - acc: 0.8468 - val_loss: 1.1076 - val_acc: 0.5739\n",
      "Epoch 16/25\n",
      "457/457 [==============================] - 22s 47ms/step - loss: 0.3823 - acc: 0.8621 - val_loss: 1.2124 - val_acc: 0.5826\n",
      "Epoch 17/25\n",
      "457/457 [==============================] - 23s 50ms/step - loss: 0.4066 - acc: 0.8556 - val_loss: 1.1213 - val_acc: 0.5826\n",
      "Epoch 18/25\n",
      "457/457 [==============================] - 22s 48ms/step - loss: 0.3801 - acc: 0.8687 - val_loss: 1.2800 - val_acc: 0.5652\n",
      "Epoch 19/25\n",
      "457/457 [==============================] - 22s 47ms/step - loss: 0.3625 - acc: 0.8731 - val_loss: 1.9879 - val_acc: 0.4174\n",
      "Epoch 20/25\n",
      "457/457 [==============================] - 22s 48ms/step - loss: 0.3603 - acc: 0.8709 - val_loss: 1.1445 - val_acc: 0.5913\n",
      "Epoch 21/25\n",
      "457/457 [==============================] - 22s 47ms/step - loss: 0.3123 - acc: 0.8840 - val_loss: 1.4360 - val_acc: 0.5391\n",
      "Epoch 22/25\n",
      "457/457 [==============================] - 22s 48ms/step - loss: 0.3183 - acc: 0.8731 - val_loss: 1.3268 - val_acc: 0.5826\n",
      "Epoch 23/25\n",
      "457/457 [==============================] - 22s 47ms/step - loss: 0.3352 - acc: 0.8731 - val_loss: 1.3009 - val_acc: 0.5217\n",
      "Epoch 24/25\n",
      "457/457 [==============================] - 22s 47ms/step - loss: 0.3218 - acc: 0.8818 - val_loss: 1.3684 - val_acc: 0.6000\n",
      "Epoch 25/25\n",
      "457/457 [==============================] - 22s 47ms/step - loss: 0.3552 - acc: 0.8687 - val_loss: 1.2239 - val_acc: 0.5565\n"
     ]
    }
   ],
   "source": [
    "history  = model.fit(X_train_encoded_padded_words,Y_train, epochs = epochs, batch_size=batch_size, verbose=1,\n",
    "validation_data=(X_val_encoded_padded_words, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 1s 8ms/step\n",
      "Test accuracy: 0.5565217386121335 %\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_val_encoded_padded_words, Y_val, verbose=1)\n",
    "print('Test accuracy:', score[1],'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to token\n",
    "def convert_data_to_token(raw_row):\n",
    "    sentence_col_group = [\"x\",\"y\",\"w\",\"l\",\"area_percent\"]\n",
    "    \n",
    "    sentence = raw_row[\"sentence\"]\n",
    "#     Append \"x\",\"y\",\"w\",\"l\",\"area_percent\" into sentence\n",
    "    for col_name in sentence_col_group:\n",
    "        sentence += ' ' + str(int(raw_row[col_name]*10))\n",
    "        \n",
    "    tokens = Tokenizer.texts_to_sequences([sentence])\n",
    "    tokens = pad_sequences(tokens, maxlen=5500)\n",
    "\n",
    "    return tokens\n",
    "    # Group \"title\", \"date\", \"phone_num\",\"address\" into info col\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_test(raw):\n",
    "    col = [\"title\", \"date\", \"phone_num\",\"address\",\"index\",\"content\",\"total\",\"brand_name\",\"thank_you\"]\n",
    "    print(raw['sentence'],end=' ')\n",
    "    for c in col:\n",
    "        if raw[c] == 1:\n",
    "            print(c)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cám ơn quý khách thank_you\n",
      "[[0.11353861 0.04898914 0.18534403 0.00534785 0.00359662 0.6431837 ]]\n",
      "Result: index\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "ran = randint(0, len(raw_train_df))\n",
    "test = raw_train_df.loc[ran]\n",
    "print_test(test)\n",
    "tokens = convert_data_to_token(test)\n",
    "prediction = model.predict(np.array(tokens))\n",
    "i,j = np.where(prediction == prediction.max()) #calculates the index of the maximum element of the array across all axis\n",
    "# i->rows, j->columns\n",
    "i = int(i)\n",
    "j = int(j)\n",
    "print(prediction)\n",
    "total_possible_outcomes = [\"area_percent\", \"title\", \"date\", \"phone_num\",\"address\",\"index\",\"content\",\"total\",\"brand_name\",\"thank_you\"]\n",
    "print(\"Result:\",total_possible_outcomes[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(Tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
